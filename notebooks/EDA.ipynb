{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "This notebook provides an EDA of the dataset and also creates the clean and anon. data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.data.utils import anonymize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../PATH_TO_DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame Shape:\", df.shape)\n",
    "try:\n",
    "    display(df.head(10))\n",
    "\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    display(df.info())\n",
    "\n",
    "    print(\"\\nCheck for Missing Values:\")\n",
    "    display(df.isnull().sum())\n",
    "except Exception as _:\n",
    "    print(\"We are in a docker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Distribution of Target Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df[\"sensitive_label\"].value_counts()\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"Set2\")\n",
    "plt.title(\"Distribution of sensitive_label\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Label Counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_length\"] = df[\"text\"].apply(lambda x: len(str(x)))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df[\"text_length\"], bins=50, kde=True)\n",
    "plt.title(\"Distribution of Text Lengths\")\n",
    "plt.xlabel(\"Text Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Basic statistics for text length:\")\n",
    "print(df[\"text_length\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Text Cleaning for EDA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def basic_cleaning(text):\n",
    "    # Not needed more data cleaning\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(basic_cleaning)\n",
    "try:\n",
    "    display(df[[\"text\", \"cleaned_text\"]].head(5))\n",
    "except Exception as _:\n",
    "    print(\"We are in a docker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "if \"cleaned_text\" in df.columns:\n",
    "    # Flatten all tokens into a single list\n",
    "    all_tokens = []\n",
    "    for t in df[\"cleaned_text\"]:\n",
    "        all_tokens.extend(tokenize(t))\n",
    "\n",
    "    # Top 20 most common words\n",
    "    counter = Counter(all_tokens)\n",
    "    common_words = counter.most_common(20)\n",
    "\n",
    "    # Display barplot\n",
    "    words, counts = zip(*common_words)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=list(words), y=list(counts), palette=\"Set2\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"Top 20 Most Common Words (after cleaning)\")\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Most Common Words:\")\n",
    "    for w, c in common_words:\n",
    "        print(w, \":\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label-Wise Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_labels(df, text_column, label_column):\n",
    "    \"\"\"\n",
    "    Analyze text characteristics by label.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing the data\n",
    "        text_column: Name of column containing text\n",
    "        label_column: Name of column containing labels\n",
    "    \"\"\"\n",
    "    # Split by label\n",
    "    label_0_texts = df[df[label_column] == 0][text_column].tolist()\n",
    "    label_1_texts = df[df[label_column] == 1][text_column].tolist()\n",
    "\n",
    "    # Compute average text length by label\n",
    "    avg_len_label_0 = np.mean([len(t.split()) for t in label_0_texts])\n",
    "    avg_len_label_1 = np.mean([len(t.split()) for t in label_1_texts])\n",
    "\n",
    "    print(\"Average Word Count Label 0:\", avg_len_label_0)\n",
    "    print(\"Average Word Count Label 1:\", avg_len_label_1)\n",
    "\n",
    "    # Distribution of text length by label\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    sns.histplot(\n",
    "        [len(t.split()) for t in label_0_texts], bins=30, ax=ax[0], color=\"skyblue\"\n",
    "    )\n",
    "    ax[0].set_title(\"Text Length for Label 0\")\n",
    "    ax[0].set_xlabel(\"Word Count\")\n",
    "\n",
    "    sns.histplot(\n",
    "        [len(t.split()) for t in label_1_texts], bins=30, ax=ax[1], color=\"salmon\"\n",
    "    )\n",
    "    ax[1].set_title(\"Text Length for Label 1\")\n",
    "    ax[1].set_xlabel(\"Word Count\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Compare word distributions\n",
    "    label_0_tokens = []\n",
    "    for t in label_0_texts:\n",
    "        label_0_tokens.extend(tokenize(t))\n",
    "    label_1_tokens = []\n",
    "    for t in label_1_texts:\n",
    "        label_1_tokens.extend(tokenize(t))\n",
    "\n",
    "    label_0_freq = Counter(label_0_tokens).most_common(10)\n",
    "    label_1_freq = Counter(label_1_tokens).most_common(10)\n",
    "\n",
    "    print(\"\\nTop 10 Words in Label 0:\")\n",
    "    for w, c in label_0_freq:\n",
    "        print(w, \":\", c)\n",
    "\n",
    "    print(\"\\nTop 10 Words in Label 1:\")\n",
    "    for w, c in label_1_freq:\n",
    "        print(w, \":\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_labels(df, \"cleaned_text\", \"sensitive_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams and Trigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "\n",
    "def get_top_ngrams(corpus, n=2, top=10):\n",
    "    \"\"\"\n",
    "    Returns a list of top n-grams from a corpus.\n",
    "    \"\"\"\n",
    "    all_tokens = []\n",
    "    for text in corpus:\n",
    "        all_tokens.extend(tokenize(text))\n",
    "\n",
    "    n_gram_counts = Counter(ngrams(all_tokens, n))\n",
    "    return n_gram_counts.most_common(top)\n",
    "\n",
    "\n",
    "# Bigrams\n",
    "top_bigrams = get_top_ngrams(df[\"cleaned_text\"], n=2, top=10)\n",
    "print(\"Top 10 Bigrams:\")\n",
    "for bg, count in top_bigrams:\n",
    "    print(\" \".join(bg), \":\", count)\n",
    "\n",
    "# Trigrams\n",
    "top_trigrams = get_top_ngrams(df[\"cleaned_text\"], n=3, top=10)\n",
    "print(\"\\nTop 10 Trigrams:\")\n",
    "for tg, count in top_trigrams:\n",
    "    print(\" \".join(tg), \":\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Similar Patterns with Different Labels\n",
    "\n",
    "This analysis identifies and groups similar text patterns that have been labeled differently, \n",
    "which could indicate inconsistencies in the labeling process. The process:\n",
    "\n",
    "1. Text Similarity Analysis:\n",
    "   - Anonymizes texts to focus on patterns rather than specific values\n",
    "   - Uses TF-IDF vectorization with n-grams (1-3) to capture text features\n",
    "   - Calculates cosine similarity between texts to find similar patterns\n",
    "   \n",
    "2. Grouping and Analysis:\n",
    "   - Groups texts with similarity above threshold (0.7)\n",
    "   - Identifies groups with inconsistent labels\n",
    "   - Suggests relabeling based on majority vote within each group\n",
    "   \n",
    "3. Output Generation:\n",
    "   - Creates multiple dataset versions:\n",
    "     * Relabeled: Original dataset with suggested label corrections\n",
    "     * Clean: Dataset with all inconsistent groups removed\n",
    "     * Anonymized versions of both\n",
    "   - Generates visualizations of group sizes and label distributions\n",
    "   - Exports detailed suggestions for manual review\n",
    "\n",
    "This helps improve dataset quality by identifying potential labeling errors \n",
    "and providing options for handling inconsistencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_groups(texts, labels, threshold=0.7):\n",
    "    # Anonymize texts before comparison\n",
    "    anonymized_texts = [anonymize_text(text) for text in texts]\n",
    "\n",
    "    # Create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=2)\n",
    "    tfidf_matrix = vectorizer.fit_transform(anonymized_texts)\n",
    "\n",
    "    # Calculate pairwise similarities\n",
    "    similarities = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Create groups of similar texts\n",
    "    groups = []\n",
    "    used_indices = set()\n",
    "\n",
    "    for i in range(len(texts)):\n",
    "        if i in used_indices:\n",
    "            continue\n",
    "\n",
    "        # Find all similar texts to the current one\n",
    "        group = []\n",
    "        for j in range(len(texts)):\n",
    "            if similarities[i, j] >= threshold:\n",
    "                group.append(\n",
    "                    {\n",
    "                        \"index\": j,\n",
    "                        \"text\": texts[j],\n",
    "                        \"anonymized_text\": anonymized_texts[j],\n",
    "                        \"label\": labels[j],\n",
    "                        \"similarity\": similarities[i, j],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Only keep groups with more than one text\n",
    "        if len(group) > 1:\n",
    "            groups.append(group)\n",
    "            used_indices.update(item[\"index\"] for item in group)\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n",
    "def analyze_groups(groups):\n",
    "    inconsistent_groups = []\n",
    "\n",
    "    for group in groups:\n",
    "        # Count labels in the group\n",
    "        label_counts = defaultdict(int)\n",
    "        for item in group:\n",
    "            label_counts[item[\"label\"]] += 1\n",
    "\n",
    "        # Only keep groups with different labels\n",
    "        if len(label_counts) > 1:\n",
    "            # Calculate majority label\n",
    "            majority_label = max(label_counts.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "            inconsistent_groups.append(\n",
    "                {\n",
    "                    \"texts\": group,\n",
    "                    \"label_counts\": dict(label_counts),\n",
    "                    \"majority_label\": majority_label,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return inconsistent_groups\n",
    "\n",
    "\n",
    "# Apply the analysis\n",
    "groups = find_similar_groups(df[\"cleaned_text\"].values, df[\"sensitive_label\"].values)\n",
    "inconsistent_groups = analyze_groups(groups)\n",
    "\n",
    "# Display results\n",
    "print(f\"Found {len(inconsistent_groups)} groups with inconsistent labels\\n\")\n",
    "\n",
    "for idx, group in enumerate(inconsistent_groups, 1):\n",
    "    print(f\"\\nGroup {idx}:\")\n",
    "    print(f\"Label distribution: {group['label_counts']}\")\n",
    "    print(f\"Suggested label (majority): {group['majority_label']}\")\n",
    "    print(\"\\nTexts in this group:\")\n",
    "\n",
    "    for item in group[\"texts\"]:\n",
    "        print(f\"\\nOriginal Text (current label: {item['label']}):\")\n",
    "        print(f\"  {item['text']}\")\n",
    "        print(\"Anonymized Text:\")\n",
    "        print(f\"  {item['anonymized_text']}\")\n",
    "        if item[\"label\"] != group[\"majority_label\"]:\n",
    "            print(f\"  ** Suggested relabel to: {group['majority_label']} **\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Summary statistics\n",
    "total_texts_to_relabel = sum(\n",
    "    sum(1 for item in group[\"texts\"] if item[\"label\"] != group[\"majority_label\"])\n",
    "    for group in inconsistent_groups\n",
    ")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total groups with inconsistencies: {len(inconsistent_groups)}\")\n",
    "print(f\"Total texts suggested for relabeling: {total_texts_to_relabel}\")\n",
    "\n",
    "# Export suggestions to CSV if needed\n",
    "relabel_suggestions = []\n",
    "for group_idx, group in enumerate(inconsistent_groups, 1):\n",
    "    for item in group[\"texts\"]:\n",
    "        if item[\"label\"] != group[\"majority_label\"]:\n",
    "            relabel_suggestions.append(\n",
    "                {\n",
    "                    \"group_id\": group_idx,\n",
    "                    \"text\": item[\"text\"],\n",
    "                    \"current_label\": item[\"label\"],\n",
    "                    \"suggested_label\": group[\"majority_label\"],\n",
    "                    \"group_size\": len(group[\"texts\"]),\n",
    "                    \"majority_percentage\": group[\"label_counts\"][\n",
    "                        group[\"majority_label\"]\n",
    "                    ]\n",
    "                    / len(group[\"texts\"]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "if relabel_suggestions:\n",
    "    suggestions_df = pd.DataFrame(relabel_suggestions)\n",
    "\n",
    "    # Create relabeled version (keeping only text and sensitive_label columns)\n",
    "    df_relabeled = df[[\"text\", \"sensitive_label\"]].copy()\n",
    "    for _, row in suggestions_df.iterrows():\n",
    "        df_relabeled.loc[df_relabeled[\"text\"] == row[\"text\"], \"sensitive_label\"] = row[\n",
    "            \"suggested_label\"\n",
    "        ]\n",
    "\n",
    "    # Create clean version (removing all rows involved in inconsistencies)\n",
    "    rows_to_remove = set()\n",
    "    for group in inconsistent_groups:\n",
    "        rows_to_remove.update(item[\"text\"] for item in group[\"texts\"])\n",
    "    df_clean = df[~df[\"text\"].isin(rows_to_remove)][[\"text\", \"sensitive_label\"]]\n",
    "\n",
    "    # Create anonymized versions\n",
    "    df_relabeled_anon = df_relabeled.copy()\n",
    "    df_relabeled_anon[\"text\"] = df_relabeled_anon[\"text\"].apply(anonymize_text)\n",
    "\n",
    "    df_clean_anon = df_clean.copy()\n",
    "    df_clean_anon[\"text\"] = df_clean_anon[\"text\"].apply(anonymize_text)\n",
    "\n",
    "    # Save all versions\n",
    "    print(\n",
    "        f\"\\nSaving relabeled dataset ({len(df_relabeled)} rows) to '../PATH_TO_DATA/train_relabelled.csv'\"\n",
    "    )\n",
    "    df_relabeled.to_csv(\"../PATH_TO_DATA/train_relabelled.csv\", index=False)\n",
    "\n",
    "    print(\n",
    "        \"Saving anonymized relabeled dataset to '../PATH_TO_DATA/train_relabelled_anon.csv'\"\n",
    "    )\n",
    "    df_relabeled_anon.to_csv(\n",
    "        \"../PATH_TO_DATA/train_relabelled_anon.csv\", index=False\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\\nSaving clean dataset ({len(df_clean)} rows) to '../PATH_TO_DATA/train_clean.csv'\"\n",
    "    )\n",
    "    df_clean.to_csv(\"../PATH_TO_DATA/train_clean.csv\", index=False)\n",
    "\n",
    "    print(\n",
    "        \"Saving anonymized clean dataset to '../PATH_TO_DATA/train_clean_anon.csv'\"\n",
    "    )\n",
    "    df_clean_anon.to_csv(\"../PATH_TO_DATA/train_clean_anon.csv\", index=False)\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"Original dataset size: {len(df)}\")\n",
    "    print(f\"Number of relabeled rows: {len(suggestions_df)}\")\n",
    "    print(f\"Number of rows removed in clean version: {len(rows_to_remove)}\")\n",
    "    print(f\"Clean dataset size: {len(df_clean)}\")\n",
    "\n",
    "    # Show label distribution for each version\n",
    "    print(\"\\nLabel Distribution:\")\n",
    "    print(\"\\nOriginal:\")\n",
    "    print(df[\"sensitive_label\"].value_counts(normalize=True))\n",
    "    print(\"\\nRelabeled:\")\n",
    "    print(df_relabeled[\"sensitive_label\"].value_counts(normalize=True))\n",
    "    print(\"\\nClean:\")\n",
    "    print(df_clean[\"sensitive_label\"].value_counts(normalize=True))\n",
    "\n",
    "    # Show example of anonymization\n",
    "    print(\"\\nAnonymization Example (first 3 rows):\")\n",
    "    comparison = pd.DataFrame(\n",
    "        {\n",
    "            \"Original\": df_relabeled[\"text\"].head(3),\n",
    "            \"Anonymized\": df_relabeled_anon[\"text\"].head(3),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation dataset\n",
    "val_df = pd.read_csv(\"../PATH_TO_DATA\")\n",
    "\n",
    "# Create anonymized version\n",
    "val_df_anon = val_df.copy()\n",
    "val_df_anon[\"text\"] = val_df_anon[\"text\"].apply(anonymize_text)\n",
    "\n",
    "# Save anonymized version\n",
    "print(\n",
    "    f\"Saving anonymized validation dataset ({len(val_df_anon)} rows) to '../PATH_TO_DATA/validation_anon.csv'\"\n",
    ")\n",
    "val_df_anon.to_csv(\"../PATH_TO_DATA/validation_anon.csv\", index=False)\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nValidation Dataset Statistics:\")\n",
    "print(f\"Dataset size: {len(val_df)}\")\n",
    "\n",
    "# Show label distribution\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(val_df[\"sensitive_label\"].value_counts(normalize=True))\n",
    "\n",
    "# Show example of anonymization\n",
    "print(\"\\nAnonymization Example (first 3 rows):\")\n",
    "comparison = pd.DataFrame(\n",
    "    {\"Original\": val_df[\"text\"].head(3), \"Anonymized\": val_df_anon[\"text\"].head(3)}\n",
    ")\n",
    "try:\n",
    "    display(comparison)\n",
    "except Exception as _:\n",
    "    print(\"We are in a docker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New data distribution in train df after relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df_relabeled_anon[\"sensitive_label\"].value_counts()\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"Set2\")\n",
    "plt.title(\"Distribution of sensitive_label in relabeled dataset\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Label Counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_labels(df, \"cleaned_text\", \"sensitive_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Dataset Overview and Label Distribution\n",
    "* The dataset consists of 680 entries with two columns: text (containing various log messages) and sensitive_label (indicating the presence of sensitive information).\n",
    "* The labels are somewhat imbalanced, with 440 (64.7%) non-sensitive and 240 (35.3%) sensitive records.\n",
    "* The dataset was noisy, meaning that some labels may not be entirely accurate.\n",
    "\n",
    "2. Text Length and Characteristics\n",
    "* The average text length is 101.68 characters, with a standard deviation of 92.3.\n",
    "* Messages labeled as sensitive (sensitive_label=1) tend to be longer (15.95 words on average) compared to non-sensitive ones (10.83 words).\n",
    "* Sensitive texts often contain specific terms related to security incidents, credentials, and personally identifiable information.\n",
    "\n",
    "3. Common Words and Patterns\n",
    "* Most common words include User, access, log, policy, SSN, and password.\n",
    "* Top bigrams include \"requested access\", \"password reset\", and \"account credentials\", suggesting a focus on access control.\n",
    "* Top trigrams like \"Service account credentials\", \"accidentally shared SSN\", and \"public Slack channel\" indicate frequent sensitive data exposures.\n",
    "\n",
    "4. Labeling Inconsistencies\n",
    "* Multiple text entries with nearly identical structure have different labels (e.g., “User X requested access” is sometimes labeled as sensitive and other times not).\n",
    "* A similarity analysis using TF-IDF and cosine similarity identified 56 groups of inconsistently labeled texts.\n",
    "* Approximately 96 texts were suggested for relabeling.\n",
    "\n",
    "5. Anonymize Function\n",
    "* The anonymize_text function was applied to the dataset to remove personally identifiable information.\n",
    "* It replaces:\n",
    "    * Names with [Name]\n",
    "    * Emails and domains with [DOMAIN]\n",
    "    * Dates with [DATE]\n",
    "    * Social security numbers with [SSN]\n",
    "    * Passwords and credentials with [PASSWORD]\n",
    "    * Numeric sequences (e.g., credit card numbers) with [NUMBER]\n",
    "* The function is useful for preserving privacy while allowing text pattern analysis.\n",
    "* However, it may not always correctly identify names if they appear at the beginning of a sentence or in uncommon formats.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cakewalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
